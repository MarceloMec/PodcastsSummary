{"podcast_details": {"podcast_title": "Agility Island - for practitioners & coaches in Product Management, Lean, Agile & Scrum", "episode_title": "Tom Gilb on eliciting what stakeholders need & solving customer problems, opportunities and threats, the principles of success planning & impact estimation tables", "episode_image": "https://d3t3ozftmdmh3i.cloudfront.net/production/podcast_uploaded_nologo/15384884/15384884-1655197726158-91e9ad6bbe61.jpg", "episode_transcript": " Tom Gilb, welcome to the Aegislae Island podcast. How are you doing today? Pretty good. Coming out of COVID. So Tom, thank you very much for coming on the show. For people who aren't familiar, they should be familiar because as far as I'm aware, the most, if not all, of the signatories of the Aegean Manifesto, plus some other notable people who weren't there in February 2001, they considered you to be the grandfather of Agile, I understand. Well, in the sense that my books introduced them to the ideas and gave convincing evidence that they were useful. Yeah, they particularly point to a book called Principles of Software Engineering Management, 1988, that had considerable history of the use of Agile methods in software and other areas. So maybe that convinced them there was something there that they ought to take a hard look at. Indeed, it seems to me that you're ahead of your time. You were talking about all sorts of ideas that some companies are only getting used to now. The laggards, if you like, are already getting used to now, but you were involved in the very early days with fairly big organizations as well. That brought you to writing, eventually writing the book Success, which you wrote for a friend, I understand. We're going to talk to that book today. And it's a delightful digest of little kind of ingredients, if you like, that are kind of mixed together, the potion put together for us. So how can we as practitioners be better at eliciting what stakeholders really, really need, who the right stakeholders are and how can we solve customer problems, opportunities and threats and so on. So delighted to have you here today. And just to kind of set a bit of context. Well, a little bit more background about the book, because the friend I wrote it for is a very senior person in the agile business. He's been at the core of many of the newer agile developments, but he's also very frustrated by bad practices and sharp practices and things like that. I said to him, you know, stop using your energy to fight bad practices or poor practices. It's time to pivot, which is a really big agile swing. And he said, what do you mean, Tom? And I said, well, ask yourself a very simple question. What does everybody want who's out there interested in some form of agile? Don't they want success in what they do? Yes. Don't they want success even if they don't do any form of agile, good or bad? Yes. Well, why don't we just focus on the success bit and leave agile to fend for itself to show that it contributes to success. And if it doesn't dump it. Hmm. Not such a bad idea, Tom. I said, I'll write a book for you to make it very clear that we need to shift or pivot our focus to being successful in our projects, not to doing agile. So I wrote the book. Yeah, it's really good. And I'm making the link available as well in the description of the podcast and the YouTube version as well. So Tom, I just wanted to talk about some patterns that have noticed thing, I guess, with requirements, elaboration, a citation, so on a couple of popular approaches. One of them user stories. So extreme programming start talking about stories and user stories would not be a popular approach for eliciting requirements or desirements, as Ken Schaver would say, in kind of complementary practice that you can use. Mike Cohn really popularized it. I believe Rachel Davies was involved in coming up with the template. I'm not sure who claims the credit for that, but I know Rachel Davies was involved. Mike Cohn, very famous for writing books on the topic and lots of video and social media on that. And essentially in user stories, they try to be clear about who the item is for, what people want, the person who is identified wants the role, the persona and why they want it, which is kind of a nice way of kind of remembering things, I guess. There are some problems around that. Some people don't bother putting the persona, they say, as a developer, as a product owner, and they get a bit lazy and they might as well not say anything. But it's a template that's there for people and people who are professional will really think a lot about the personas before they brainstorm those. And so it's a popular approach. I'm not saying it's a good or bad approach. It's a popular approach that people use. There's another approach as well, which I've seen quite a lot, which is given when then statements popularized by people in the communities around behavior-driven development specification, for example, automated acceptance tests and given a particular context, they list out all the assumptions, which I really like in the given piece, and then say when something happens, and then what should happen kind of thing. And you can feed that with tables as well, which is quite nice. You can automate those tests, which is really, really cool. So there'd be kind of two popular approaches. You can also annotate wireframes, of course, you can write in free format. The danger of free format is that, you know, what will you write and so on, and you want to forget things. And what I've noticed, Tom, is there's a kind of a split between people who like user stories and people who like given when then statements is the most popular approaches. There are other approaches, of course, that we're going to talk about today, including what you've worked on. And what I kind of noticed is that people like the idea of writing down some placeholder items with a view to coming back to them later. So and because a lot of people like to write placeholder items, that means they don't have much specifics when they write the placeholder. So they have a tentative preference for user stories. And then later on, they might rewrite them as given when then statements, or they might just rewrite the acceptance criteria as given when then statements. And so that's kind of what I'm seeing emerging, Tom, with a lot of people who come to my classes, good or bad, right? So what do you think about these trends, Tom, about people using user stories and give when then statements and that kind of way? Okay, now there's nothing wrong with having a short form of a requirement. I use it myself as a starting kit in developing a good requirement. The danger is when the most detailed form of the requirement is highly ambiguous, when it contains designs rather than real requirements, and nobody does anything about it. That's the real danger. So you need to process the requirement. I use my planning language, Planguage, to process the requirement beyond what I call the user story or ambition level. And I go down and define, for example, it as a scale of measure with points on the scale that you wish to achieve for improvement in, for example, security or something in the future. So the problem is ambiguity. The problem is stating a means rather than an ends. And the problem is a lack of discipline and knowledge of what a good requirement is. Indeed. And I've also noticed Tom that even when people write user stories, I had it only a few days ago, actually, in a training class where there was a chap in one of my classes, and he was really struggling because he wanted to do good things. He wanted to write better requirements, wanted a better expression. But he was kind of in a swamp of teams who had no appetite to care about the customer. They were writing, breaking items down into subsystem level, almost, you know what I mean? Kind of almost activities and outputs kind of completely forgetting what problems are trying to solve. It's something that sadly that I see quite a lot and to the extent where sometimes I have to keep going going going up the requirements hierarchy quite, quite high actually, until I find where the real value is that results in lots of dependencies and a bit of a mess, quite frankly. Well, there's something that people have entirely forgotten except competent organizations. And that's there is such a thing as a review or quality control of requirements. Okay. I wrote a whole book on it called Software Inspections in 1990. Now, if there is no review, if people are free to write whatever they please just to tick the box, yes, I have written a requirement, then extremely poor quality requirements will inevitably be the norm 99% of the time. So a review has to review the requirements against the standard, like are these completely clear, quantified, an ambiguous starter kit there? And do they state exactly who the stakeholders are for the requirement, that kind of thing. Those would be the rules for the review. And if a requirement fails those rules, it needs to be marked as a defective requirement and rewritten. Now, even in a very advanced world, the world of Intel, where they use my planning language for writing their requirements, they use this review, we call it specification quality control. And even then they find a very high density of defects against these rules, even though the people are trained to avoid them. They're trained on a two day course in language to write clearly, for example. And even though they're highly motivated because they know the review is coming up, even though they've had a previous review, which has shown too many defects, they still commit the defects and often have to run through a series of four review cycles before they get to the exceptionally high, almost perfect quality of a requirement required by Intel. In other words, total lack of any review whatsoever is like giving a kid a extremely fast car on a highway and said there are no police within or speed traps within miles have fun. Yeah, it's interesting, Tommy, just reminded me that when I talk with software developers, for example, they talk about, you know, they write the code and then they write their unit tests and they do their code review and so on. I don't see, I don't hear so many people talking about reviewing the product backlog items with their scrum, for example, or the work items that they can ban. And there is a pattern that's an activity that's highly recommended in scrum called product backlog refinement, where you'd spend some time every sprint of its scrum teams and they might do two afternoons a week, Tom or less people would stop maybe down tools for a day or half a day during the middle of a sprint to actually review the items together to get more detailed, to get down to another level of detail, to listen more examples, to understand what problems you're trying to really solve, all that kind of stuff. And what should be happening is you should be looking ahead, maybe two to three sprints kind of thing. And so that when an item comes into sprint planning, you know, it can be deemed as it ready to be to be acted upon. What a lot of people forget is that in scrum and sprint planning, for example, you still have time to do refinement, even at that opportunity, because it's quite a long time box, eight hours for a one month sprint for shorter sprint, usually shorter, but could still be eight hours. And so a lot of people forget actually that there's still a chance at the start of the sprint to actually really get clear about what it is we're trying to do. But in ideal situation, you're already clear. It's like we've talked about this three or four times already, like, let's just crack on with this, right. But what I don't see so often that you pointed out to is this idea of a review of how good are the requirements. What I have seen, Tom, is I've seen a thing called definition of ready being used, but I've seen it being kind of weaponized, or say, you know, you can't bring it in because it's not ready, you know, that kind of way. And so what's your reaction to that? I mean, have you have you noticed this pattern of teams where they do refinement, they have these definition of ready, but they actually turn into a gate? Is that something that kind of what you're looking for, Tom, that you actually wanted to be a gate that you need to want people to start something unless they're absolutely clear what it is? In my method, language, in the competitive engineering book, which everybody gets a free digital copy of, we have an idea we call exit and entry conditions and exit and entry processes. So it's a part of rigor. It's part of making sure you got the job done right the first time. Okay. And these are these are based on things like the reviews. And if reviews are showing up too many defects, you don't exit, people don't get their work commissioned or allowed or approved. And that motivates them, you know, that's embarrassing. And they go back and do the jobs more properly until they get the job done. And if necessary, they learn how to get the job done properly. By the way, those who are motivated to do this have taken the trouble to statistically look at the connection between defects in requirements and defects in code and delays and bugs in the system later. And they found that it's, you know, it's very roughly 10 to 100 times cheaper to deal with this problem upfront with specification quality control and exits. Than it is to suffer the ideas downstream. Now people don't know this because it's a widely known widely published phenomena are immature. They are going to be late. They're going to blame something else or somebody else and nobody will be any wiser because the culture doesn't care. Okay. But I mean, it pays off hugely to do these reviews in terms of saving time and getting stuff done right. Managers like chief technical officers who don't deal with this and make it happen are not competent chief technical officers. The programmers of the world in their world of scrum and user stories are not going to start instituting this regime on themselves. So that brings me over to your book success because on page six of the book, there's a section defining success upfront, which is kind of what you're talking about now. And I just read out what I see here. You say, here are some of the components of defining success of any project or process. And number one, a set of quantified value objectives, how good we aspire to be in the future user quantified with conditions, and then a set of constraints. Some of them are binary limits to activity. There's other ones like resource budgets, time, money, people, the conditions and so on. And then a set of conditions expressed in a scale and scale qualifiers like to define who, what, when, where, how, for the requirements, objectives and constraints. And you mentioned that this planning language will enable us to give a modified precise definition of success and failure. And so can you give us an example, Tom, maybe of something like that. Let's say I wanted to upload a video for software developers to understand more about value and requirements. Okay. Well, yeah. So let's just focus on the value objectives and leave the other stuff out as necessary, but not time for no detail. Okay. So value objectives are anything that's your stakeholders, which you could have 200 or 50 of value. Now value means ultimately they'll pay you to build in simple terms, or they will not pay you if you don't build in the same terms. That's the other way of looking at it. Okay. Now value object is a simple way of thinking about them for us techies is that there are qualities like security, safety, transparency, reliability, usability, anything you would see. Right. So those are typical things people value. Now, the thing we've noticed about the values is that they're all variables. That is, you can always say, well, I want to enhance that value or that value is going down in a bad direction. Okay. Now that implies there is some way to articulate this value numerically. And we do that with a thing called a scale of measure. So if I want to say my car goes really fast, I could say in miles per hour, I've now articulated a scale of measure and somebody says, well, but how many miles per hour? I say 300. Wow. I'm properly impressed. That's better than what I thought very fast meant. So it's as simple as that. But what we get here is extreme clarity and we get clarity of purpose. Now, if you don't have clarity of your purpose, you don't have clarity of success and you don't have clarity of failure. That means you can do anything you'd like no matter how bad it is. And nobody will say you have failed. They can't. There's nothing to hang it on. And you can claim success and since they don't know what it is, they will say, well, that sounds nice. Good. Let's move on. Okay. Long story short, the idea here is that we need to define the success criteria and the constraints, by the way, are a kind of failure criteria. Right? If you exceed the speed limit, you have exceeded a binary constraint. That's 2.1. And by defining success and failure upfront, your designers, architects, managers can work towards it systematically, get constant feedback on whether they're approaching it or not. Okay. And be able to tell whether they have achieved it or not and brag about it quite rightly if they get there. And most people, mostly, I mean, 99% of all the projects do not have this simple idea in place of quantifying, say the top 10 critical stakeholder values putting a number on the success levels that are given, you know, by the end of the year, within 10 years, you can have long range and short range numbers there. And saying we have now defined what it means to succeed. We have some constraints in there, which tell us what it means to fail. We're going to operate in that environment and it will motivate us to work towards success. It'll motivate us to not waste our time doing things that do not lead to success incrementally, agile. Okay. It will be a very much more cost effective or efficient way of working in software development. Thank you, Tom. You kind of summed up what's on page eight, actually, of your book where you talk about the principles of success planning and definition. And it starts off with realistic goals that success must compromise using engineering trade-offs to deal with conflicting stakeholder needs and to deal with the limited resources cannot be perfect optimized or maximized for the few. So for example, having five lines uptime might be ridiculous when you're at 90% uptime at the moment. Continuous updates, success value levels must not be locked into a past situation, but must be updated to reflect our latest available knowledge. And forward projection, success value levels need to reflect the future environment of the system. A rapid adaptation, a critical success value can be specified in order to engineer the ability of the system to rapidly adapt to new or improved requirements in the future and requirements specificity. Success requirements can be success specific tailored for the specific stakeholder requirements. There's a point made here that I want to hammer in. The moment you start declaring that what is critical will be quantified and that we're going to engineer the ability of the system to do these things. I'm making a move from a craft known as programming, sometimes falsely called software engineering when it's programming coding. And we're saying the size and complexity of the systems we are currently dealing with are huge compared to what they were in the early days of IT. And as with very many other disciplines, when you get to a certain stage, the skyscraper instead of the summer cabin, you have to go to engineering. That means rigorous systematic thought about what you're doing. That's what we're failing to do. That is what we're failing to train is real software engineers. That's what the chief technical officers are failing to employ is an engineering paradigm and people who can do the engineering. So let's make no mistake about it. We have to, when we're tired of failing and one recent nice book on the subject with 16,000 projects called How They Make Big Things by Bent Fl\u00fcberg found that less than 0.5% of its 16,000 projects, many of which were IT, had achieved delivering the benefits on time and under budget. Okay. 0.5%. So we have an incredibly high failure rate whether we measure it or not, whether we talk about it or not, must be very embarrassing and it's time to stop failing and start succeeding. Now, people who want to be really good managers, really good leaders of technology need to shift to the engineering paradigm so that we get the stuff done right early. Indeed. And that leads me on to the secrets of success and page nine of your success book. You say number one, a clear agreed definition of the state of success and then number two, systems engineering architecture, conscious quantitative design towards clear objectives. So designing for success and then decomposition into much smaller things. So things you can do next week, for example, not like three months time and risk consciousness engineering. So for every architecture idea, taking the time and trouble to analyze and specify the success potential, we might be talking about impact estimation tables later on. We're going to touch a bit more on that and priority engineering, we use our analysis data to compute the best overall value of architecture with the remaining budgeted resources. So you're trying to carve what's right for the budget that you've got. But crucially, you have scientific inquiry, engineering agility. Can you tell us a little bit more about scientific inquiry and what you meant by that? You kind of going plan to check out and do study territory. Is that where you're going, Tom? Yes. Yes. Simple terms. And one of the big problems we have with the practiced Agiles, like practiced forms of scrum is that they do not have any numeric hypothesis about what's going to happen. And they do not have any numeric measurement, feedback and reconciliation of the difference between what they've achieved or the we're going to achieve. Now, that's the scientific inquiry bit. You have a hypothesis, you do experiments, you measure and you think about it. That's agile as it should be. That's agile as I described in my 1976 book, software metrics page 214. Thank you. Yeah, a lot of your books are still on Amazon as well. And you've got quite a repository up on lean pub as well to make sure those links are available on the podcast and video description. But on page 12 of your book, you've got the secret of avoiding failure, which I find interesting. And basically, what you're saying here is that we need to deliver the most cost effective increments first. Yes. Yeah. But a simple idea. And do we really find that well articulated in current agile variants further you you have some principles as well, right. So you have no evil. Outsmart evil. So I think you're talking here about what's tolerable. Yes, what's below dollar failure, right? Yes, no evil. That's the definition of these failure conditions. The constraints we talked about and outsmart evil. What I found is one of the most powerful things we can do to control costs and quality and, and, and deadlines is designing to cost designing to quality, designing to time. And it's a lost art. I mean, I don't know where anybody is trained any certificates for it. But the power of the mind to find a really smart design is terrific. I mean, everything can be improved by a factor of 10 by applying a smart mind for about an hour. That's outsmarting evil. Yeah, you also have choose good, which is prioritizing low risk partial strategy increments in your values and things you could do next week basically respond quickly. Yes. And then crucially, you said limit losses and this rings a bell with me because I listened to Talib's book skin in the game last week and he's saying you know that successful traders they bash when they're profitable. But not when they're desperate, you know what I mean? So it's like, otherwise you're saying, you know, just spend 2% of your wad basically, so you're not making experiments, right? Right. You skipped quite quickly over point three choose good. And it says here prioritize low risk partial strategy increments to build high delivery efficiency value accumulation. There's a lot of words there. If you are numerically estimating the value you will deliver for the cost you will deliver it, okay? And you have a choice of 10 different things to do next week. And you always choose the one that has a little surplus there, a little profitability, a little bit of efficiency. Then number one, you need numbers to do this. You can't just say let's have a vote. That's a little bit sloppy. You need to have estimates for how much safety will it deliver next week, okay? And what costs will it deliver it next week? And this is engineering suddenly. It's not personal preference or throwing the dice or something like that. I guess I'm alluding to planning poker here or something like that. So now the point is if you systematically are prioritizing delivery of high value, low cost things, you cannot end up with anything less than this value stream until you get to the point where you can't deliver anymore. But then you've already delivered things successfully. You don't have a big bang problem all or nothing. You've already got a value stream going and maybe you can get it going again. Indeed. And then on page 15 of your book, you talk about stakeholder analysis. I had a problem with this years ago, Tom. I worked on some massive initiative for a computer factory in Ireland. And it was a bit too good to be true, Tom. Like everything was fine. It was like not a blip of downtime, not even slow time. Everything was just perfect. But it was too good to be true. No one's something's too good to be true. It is too good to be true. It feels like it's too good to be true. And we forgot about the poor accountants at Montend. They couldn't close the month. It was a panic two days before Montend. And so, yeah, you've got a big section on this about who are your critical stakeholders, making sure you identify all of them and what they value and keeping this process forever for the system lifetime as well. You're continually checking who are the people we need to look after and what they're particularly worried about. Do you have any tips for people and how people can do that, Tom? Well, first, your chief technical officer has to make sure there is a stakeholder analysis process, not a customer and user process. The problem with things like user stories, use cases, user experience is it's totally focused on one of many types of stakeholders. The rest of the critical stakeholders will kill your whole project alone, even if your user is dead happy. So we've got to move away from this childish, immature, small-scale thinking where user is at the center of the world. They're important, of course. And take a look at the reasons why our projects are late, over budget, unprofitable and things like that. And those are the other critical stakeholders. So there has to be a stakeholder analysis process. It should be based on known stakeholders in your company, in your business. You should build lists of known stakeholder types and their known critical values, the things that trip you up, your lessons learned from failures earlier. And you should rigorously analyze what their values are, especially what I call their critical values, the ones that will get you into trouble if you don't deal with them. And this is rigorous engineering analysis of stakeholders we're talking about. By the way, cultures that are very good at this are like NASA. They know they have 500 different stakeholders and they know they must analyze them rigorously or one little O-ring will blow up the whole rocket in front of everybody. Indeed, yeah. You did some work with Boeing as well, did you Tom? Quite a bit, six years in it. So they have Boeing adopted not least my methods of review of their engineering drawings. That is overnight from me demonstrating the power of it and then measuring it to thousands of engineers doing my specification quality control. We have case studies both in McDonnell Douglas, which later became part of Boeing down in California and in Renton in Washington at Boeing where my father built airplanes during the Second World War. He engineered them. Ah cool. Look at page 17, value requirements. There's an example there of value requirements to do with air quality. I think it was London or something, Greater London. Yes. I remember looking for a house Tom in London and I ran out of the house when I saw this thing inside the wardrobe. I said, what's going on here? What's that? It was an NO2 filter. There was so much traffic outside. There's an NO2 filter in the house. Can you believe that? No. Yes, you say so. Wow. I ran, I call this the nitrogen oxide lane. Yeah. It's a well known road A40 in London. So you have the air quality, the nitrogen oxide in London, it's from 2022 and you had an ambition level of drastically improve air quality in London to acceptable legal levels as stated in the Paris Agreement. The scale is the number of persons who reside in London boroughs dying from exposure over time to pollution per year in an area. The meter was recent hospital records from London hospitals for deaths by pollution exposure related illness. And you have the status and you have what's tolerable and what the goal is. That's a constraint. That's that tolerable is a constraint. That's the evil border. OK, so the status at the time was nine and a half thousand people overall. And that was 2019. And the of the older generation, it was one point five, fifteen hundred people. Tolerable was 200 people in five years. And then for children, it was a lower, it was 100. And you were specific about the pollution being NO2 and carcinogens in the Greater London area for 2020. And the goal, I guess, what you're hoping that the number will go down to. Yeah. So that's defining good or success. Yeah. By 2028. OK. Yeah. Yeah. Very nice. Let me try to pop in a little joke. I was once working for the Norwegian Veritas, which classifies ships all over the world for safety. And I was working for the board of directors at the top level of what they were going to do. And it turned out they had something like 400 seamen died each year in ships that had been approved by them. So that was the status. I then put in as a trial goal that within 10 years, only 200 people would die in their ships off the amount. Right. And it was then put to the board of director as an improvement for the whole corporation. They were quite shocked that I should ask them to plan to kill 200 seamen on their ships. Yeah. Yeah. But at the same time, you have to aim for something that's realistic as well, don't you? Yep. Yeah. It's difficult to get down to zero. I don't think they're down to zero yet. Yeah. We just talked about constraint levels. So what's what's intolerable, what's tolerable, what's success, what would be a stretch you talk about that. But then what really struck me that I think a lot of practitioners will find really interesting is you have impact estimation tables. So there's cost estimated against budget level and you have a level of uncertainty about the estimate I guess, but also the credibility and the credibility of the source of the evidence. So if there is evidence to back up where how we're getting on, how credible is that evidence? And that's that really struck me actually. Now notice that evidence is in. Well, it's all over academia. Every paper ever published by academics has plenty of references to the evidence for what they're saying. Okay. So it's a scientific academic custom for good reason. And it's used by engineers too, to make decisions. In fact, I've got a whole book on evidence I'm just about to read. So it's out there and not to mention legal evidence. I mean, don't don't we watch detective stories on television and things like that. The place where we don't seem to have evidence is in IT, where we are not evidence based, although we have management who probably would say, yeah, we want to be evidence based, but they don't make it happen in their IT projects. So I'm again talking to my friend, the chief technical officer, make sure that people who are speculating with your money and your reputation as a top manager, give evidence for whatever they're proposing. Tom, just on the impact estimation, I get the whole idea about the evidence. Yeah, that's fine. But it's the whole notion of an impact estimation table. Where did that come from? That idea that maybe the estimates aren't so solid. Right. Right. Right. Right. Now, I'll tell you the truth. I was at Royal Festival Hall in London listening to a Christmas choral concert and I wrote down the elements of this on the back of my concert program. It came to me from my muse. I'm not kidding. But the other part of the story is I started doing things like this early in the sixties based on engineering done at Tom's TRW systems by Barry Bane, blessed soul, he departed last year and called the requirements properties a matrix. So this is an engineering idea, having a matrix to look at complex systems. And every year I went back to TRW systems in California and said, I've made a little improvement to your basic idea. And one year the idea was evidence. Said, you know, not just come up with a number, but give the evidence for the number. And so I evolved this impact estimation table over many decades of, if you like, trials with interested parties. And it got to the stage where it, among other things, we could fully automate it. Although spreadsheets are very good first pre-automation of it. We use those in the early days. And now we have apps that know what evidence is and what to do with it and things like that. The next stage will be artificial intelligence that will decipher the quality of the evidence and the source. I'm not joking. We're working on it. Nice. So on page 20 of your book, Tom, you talk about value level constraints. Basically what you're saying is you might have said three strategies, but only one of them works within all the constraints. So that's all you should really focus on, I think, is what you're trying to say. Or try to relax or remove the constraints. Let's just say for sake of argument that one of the strategies which is outside the limit is 10 times more profitable. And let's just say that with using your imagination and redesigning something, you can in fact relax the constraint and get something 10 times more profitable, then relaxing the constraints is the smart thing to do. You talk about long-term objectives on page 23. I find this interesting because these days I find so much of an addiction to the short term, which you are talking about that here is saying some stakeholder values are mainly interested in the long term, not immediately. Can you tell us a little bit more about what you were thinking there? Because you're talking about mature planners versus, I guess, immature planners. Well, let me for us, since we're in a techie session here, let me bring in the concept of technical debt, which I think everybody knows about. And everybody realizes is a huge cost and a threat to your agility to compete with your products and services. So now why is this? Well, it's because we were short term and nobody stopped us. No chief technical officer insisted on engineering the system to have low technical debt, which he could have, but he didn't. Failure of technical management. I don't blame a programmer for that. Long-term objectives. Take something in this example here. We have a whole arm called adaptability with things like upgradability, portability, extendability, et cetera. Now, by definition, these are things that are not your immediate concern. Your immediate concern is building stuff, getting out that first version. But for the lifetime of the system, which could be 10, 20, 30 years, think an air traffic control system here, the major costs and major problems will be the adaptability of the system as initially built. And you have to build a system to be easily adaptable. Now that's architecture, that's engineering. It is most certainly not coding. It is most certainly not removing bad code, some seem to think. Okay. So somebody has to grow up. If you're building an air traffic control system for I've worked on those systems, somebody needs to say, we have to look ahead to the lifetime of the system, to making it easy to maintain safely, to fix bugs safely, et cetera. And we have to set quantified objectives. One of my clients confirm it, set 10 different quantified values, which they said that's the set of things we call technical debt. And one week, every month, they use their weekly cycle to work on that technical debt. That is to redesign, redesign, redesign the system. So it was easier and easier and easier for them to maintain and fix. By the way, they woke up to this necessity eight years after launch of the project, a bit late, but then they knew they had a catastrophic problem on their hands. You know, we bring death to the whole company. So they then made the regular investment. You can't change everything in an old system instantaneously, but you can spend a week, a month for the rest of history, making it a really low technical debt system. Yeah, it's a good point actually. Yeah. Brings me on to the laws of project success on page 45. Really like this. You've got GILB's laws of project success. Number one, if you've not defined progress clearly, then it is impossible to reach it. Conscious design beats random conventional construction that ties in with the book how big things get done as well, doesn't it? Try to deal with things when they're easier to fix, I guess. Number three, if potential problems are solved or prevented early, then that is far more cost effective than reacting to failure threats much later. That wisdom has been out for quite a while, but a lot of people forgot about that. People used to talk about that a lot in my career, but I don't, I don't hear it anymore. Yeah, we should hear it more often. What, what requirement levels require? I know. Yeah. So ideal requirement levels require infinite resources. Balancing conflicting requirements would be more successful than disappointing multiple unreasonable target expectations. So this is where having what's intolerable, tolerable, what the goal is, what the stretch is, that's where it's crucial, right? Cause you've got your meter and your scale and all that kind of stuff. And a disciplined engineering approach is the most cost effective method for reaching success and keeping it and scientific methods also apply to industrial and public service projects. You talked a lot actually in the book as well about systems thinking and hypotheses and so on. But then you have the ethics of success on page 46, which I'm going to read to you. And so we will always tell our client the full truth in writing, in writing, I think is really crucial there. We will always offer to do things in the client's real long-term best interest, explaining why, and in spite of their instructions to the country, sometimes they do ask us to do something harmful. And if a client insists on acting or instructing us in a manner that would probably lead to failure or serious lack of success, then we will regretfully resign from the assignment. I agree with that. Giving your reasons in writing. Also, you wouldn't leave any doubt about why you left Tom, you'd make it clear. Yes. It's your ethical obligation as an outsider consultant to explain why upfront, by the way, with a bit of luck, you'll get the following reaction from higher up, explain this slowly and they'll bring you back and do what you say, or they'll try somebody else and totally fail and then they'll bring you back. I've been brought back. Okay. Be the one who got it right. Yeah. Management needs people they can trust to tell them the bad news early so they can act on it. And on page 56, there's a section there decomposing stakeholder needs. So a lot of people think, oh, we're going to spend a few months kind of starting this out and we'll do some release whenever four or five months time. But actually, you're saying separate the most critical needs for early delivery, maybe even in the next couple of weeks. Do critical stuff early. Yeah. Tom, what would be the most memorable examples that you have of that? If you have some examples that you don't give any secrets away, you don't have to name the organization or the industry, but do you recall times where you actually surprised people with how much value you produced within a week, for example? Okay. Now I have a whole case study that is in writing and you'll find it in references to my books. It's from the U S army department of defense, persons come, which is the U S army personnel system. They were in embarrassing situation. General Schwarzkopf at the end of the initial war in Iraq had said that their IT system, which was eight years old, was so terrible that it gave him the wrong answer late and he could do just as well looking out the window and counting soldiers to get the right answer quickly. So that was pretty embarrassing after having spent a few million dollars. So I was charged with saving this whole IT project and I used what I call my startup week. You'll find plenty of writings on that in the references in the various books. And I flew into Washington for one week and I said, I'm out of here at the end of the week, so you're on your own. Let's do the best we can. And on Monday, we quantified the top 10 critical objectives with the help of the 12 key people on the project in the room with me. Tuesday, they brainstormed the top 10 strategies. Wednesday, we did an impact estimation table to see the power of the strategies on the goals and the costs. And then Thursday is the day where we pull off a miracle. Basically, it's where we say, is there some little sliver of action we can do next week to actually make this real IT system really better in at least one of the value objectives, numerically, right? So, in other words, can you do a miracle in this really big bang environment? It turns out there were several things we could do that could be done next week. But they said, Tom, we've got a really interesting solution here. And I said, what's that? We discovered that the reason the general got a late answer from the IT system, he was that the IT system put the general at the back of the queue of 15,000 others of his soldiers inquiring of the same system. And I can imagine that gives a late reply to the general. And it's immediately obvious what we're going to do, right? If general then move to head of queue. So it doesn't sound too difficult. And I said, can you do that next week? And they said, yes. And I'm very, very skeptical because, you know, a small change could have massive mandated testing for weeks before it's allowed to be released just because it's one line of code doesn't mean it can be released next week. And I said, are you sure you can do it by the end of next week? Because I want to deliver to the general a real improvement next week. And they said, yes. And I said, how can you be so damn sure Tom? And they said, because we already did it. And a short story about miracles delivered while we're in the planning mode. Nice. I got to close today's interview by reading a section that I think really has some gold nuggets for practitioners listening. And then we just have a quick chat before we wrap up today. But basically some stakeholders are more critical to your system than others. Yeah, that makes sense. Some stakeholder needs are more critical to your system than others. That also makes a lot of sense. A lot of people forget that stakeholders are undisciplined. They may not know all their needs or know them precisely or know their value, but they can be analyzed, coached and helped to get the best possible deal. So I'm gathering there's going to be lots of coaching tips that you might have for people to be able to kind of get that out of people. Going to ask you for a story on that before we wrap up today. Stakeholders may be inaccessible, unwilling, inanimate, oppositional and worse, but we need to deal with them intelligently. Stakeholders might well ask the wrong thing and means rather than the real ends. But they can be guided to understand that or their requests can be interpreted in their own real best interests. Stakeholders do not want to wait years, get delays, invest shit loads of money and get little or no value. Stakeholders cannot have any realistic idea of what their needs and demands will cost to satisfy. So they're adopted by you requirements need to be based on value for cost, not on value alone. And if you think you've found all critical stakeholders, I think you should assume that there's at least one more. And when you find that one, there's probably one more. New stakeholders will emerge and they are not all identified at the beginning. If you think you found all the critical needs of a stakeholder, there will always be at least one more need hiding. If you do not understand and act on the principles we just talked about, you might blame your failure on system complexity and the unexpected and wicked problems. But in reality, it's your own fault and responsibility. Deal with it upfront and constantly thereafter. Yes. So Tom, that reminds me. I need to ask you about an example where a client came to you and they basically told you the means but not the ends. Without giving any secrets away Tom, can you think of a story where someone said I want blah, but actually wasn't blah. They wanted actually to do a supernance. An improved question would be, could I ever think of an instance where they actually came to me with their critical values and not some preconceived notion of how to build it or do it. I'm serious. It is the exception. Now, what's happened in the background is the forces that be the staff who wants the new kit to use and new programming languages to play with and new database stuff. And the suppliers, bless them who want to sell their services and kit, read the big con new book on the consultancies. All the, as Eisner called them, the military industrial evil forces. I didn't use the word evil, but he meant it. They have conspired to get you to buy and build something which will be late, will cost far too much, will fail enormously, will steal resources from other good systems and basically is corrupting society. I refer again to the book, The Big Con that came out this year. I've just read it. Now, so all these forces have, by the way, they've learned to gang up on the executive group and make them believe they're doing the right thing. Okay. So it is with a little bit of difficulty, we start the conversation. Yes, but exactly what do you hope to achieve and say, well, we're going to, you know, all these good things that these consultants said we get, you know, competitiveness and competitive edge and flexibility and agility and no, no, no, no, no, that's fine. But how much competitiveness, how much competitive edge, how much agility, you know, a lot of it. Now, come on, that's bullshit and you know it. Yeah, but what can we do about that? You can quantify it. And one delightful thing, say what you like about managers, but at the top are, unless they haven't been replaced recently, are some pretty smart cookies who just need to know that somebody might help them break this logjam and quantify their critical objectives. And so I happily work with those people. You know, everyone's on the day, I get the go ahead for God's sake, let's quantify all our critical objectives and move on. They were not taught at their business school university that they could quantify all critical objectives. They were brought up with a balanced scorecard thinking that improved quality was good enough specification fail, failure of our educational institutions for managers. And I don't just see the value from your work in terms of clarifying what value what problems need to be solved opportunities, but also I see useful as well for designing experiments. And you do talk a lot about experiments and hypotheses in particular in the book. And I see value there as well because between using your work to actually be clear about what we think we should build and being clear about what our hypotheses are, so we can better learn about what we should build. I see a lot of value here. And I think it's something that needs to come back more in vogue, Tom. And I'm hoping some listeners here will look up at the resources that I will post in the podcast and YouTube descriptions as soon as this published. Thank you so much for coming on the JGT Island podcast, Tom. Thanks for inviting me. Let's hope we convince one smart person to do at least one better thing. That'd be nice. Thank you. Thank you."}, "podcast_summary": "In the podcast, Tom Gilb discusses the importance of defining success in projects and focusing on delivering value. He shares insights from his book \"Success\" and emphasizes the need for clear objectives, quantified value, and constraints. Gilb also highlights the significance of stakeholder analysis and the role of evidence in decision-making. He emphasizes the need for a disciplined engineering approach and the use of scientific inquiry. Gilb's laws of project success include defining progress, conscious design, preventing problems early, and balancing conflicting requirements. He also addresses the ethics of success and the responsibility to tell the truth, act in the client's best interest, and resign if necessary. Gilb's approach promotes a systems thinking mindset and a focus on long-term objectives. Stakeholder needs are decomposed, and critical needs are addressed early. The importance of quantifying critical objectives and experimenting to learn and adapt is emphasized.", "podcast_guest": "Tom Gilb", "podcast_highlights": "The highlights of the podcast are as follows:\n\n- Tom Gilb is considered the grandfather of Agile due to his books introducing Agile concepts and providing evidence of their usefulness.\n- The podcast discusses the need to shift focus from simply doing Agile to achieving success in projects.\n- User stories and given when then statements are popular approaches for eliciting requirements, but the real issue is ambiguity and lack of discipline in requirement writing.\n- The importance of requirement reviews and quality control is emphasized, as this helps ensure clear, quantified, and unambiguous requirements.\n- Success is defined as clear, quantified value objectives, constraints, and conditions expressed on a scale. The importance of designing for success and decomposing requirements into smaller, manageable increments is highlighted.\n- Stakeholder analysis is crucial, and it is essential to identify all critical stakeholders and their values. Stakeholders may have conflicting needs, and it is important to prioritize and balance these needs.\n- The podcast emphasizes the need for evidence-based decision making in IT projects and the importance of defining success and failure upfront.\n- The ethics of success are discussed, including the obligation to tell the full truth, offer the best interests of the client, and resign from assignments if they would likely lead to failure or lack of success.\n- The laws of project success are outlined, including the need for clear progress definition, conscious design beating random construction, early problem solving and prevention, balancing conflicting requirements, and adopting a disciplined engineering approach.\n- The podcast emphasizes the importance of long-term objectives, system thinking, and the need for continuous improvement and adaptation.\n- Lastly, the podcast discusses the need to quantify critical objectives and clear value objectives in order to avoid failure and achieve success.\n\nOverall, the podcast highlights the importance of clear, quantified objectives, disciplined engineering, stakeholder analysis, and evidence-based decision making in order to achieve project success."}